<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>アイラン　ソフトウェア開発者</title>
    <link>http://localhost:1313/jp/</link>
    <description>Recent content on アイラン　ソフトウェア開発者</description>
    <generator>Hugo</generator>
    <language>jp</language>
    <lastBuildDate>Sun, 14 Sep 2025 17:07:21 +0900</lastBuildDate>
    <atom:link href="http://localhost:1313/jp/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>私について</title>
      <link>http://localhost:1313/jp/about/</link>
      <pubDate>Sun, 14 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/jp/about/</guid>
      <description>&lt;h1 id=&#34;自己紹介&#34;&gt;自己紹介&lt;/h1&gt;&#xA;&lt;p&gt;こんにちは、アイランです 👋&lt;/p&gt;&#xA;&lt;p&gt;私は長年、ソフトウェア開発の世界に熱中しています。最初はウェブアプリケーション開発を学び、その後フルスタックのブートキャンプに参加して、さらに多くの技術や働き方に触れることができました。&lt;/p&gt;&#xA;&lt;p&gt;それ以来、LeanMindで働いており、とても多様で充実したプロジェクトに参加する機会に恵まれています：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Clarity.aiでは、データの世界に深く関わり、Python、Jupyter Notebooks、Docker、AWS、pytestやHypothesisといったテストライブラリを使っていました。大量の情報を扱う方法や、コードの品質に細心の注意を払うことを学んだ、濃密な期間でした。&lt;/li&gt;&#xA;&lt;li&gt;その後、Technology Innovation Institute（TII）では、ブラウザから直接、数学ライブラリがあらかじめインストールされた仮想マシンにアクセスできるウェブプラットフォームの作成に携わりました。レポート生成やクラウドストレージも含め、Next.js、MongoDB、AWS、ArgoCDやJenkinsといったデプロイツールを使用しました。&lt;/li&gt;&#xA;&lt;li&gt;Voxel（Amadeus）で、請求や請求書署名管理の分野に携わっています。日々の業務では、.NETでの開発、SQLデータベースの操作、NSubstituteやTestContainers、Jenkins、GitHub ActionsなどのテストライブラリやCI/CDツールの利用を行っています。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;私は自分の歩みを、一つひとつのプロジェクトが新しい視点や学びを与えてくれる冒険だと考えています。技術が仕事の中心ではありますが、何よりも、人々の役に立つものを作れることに喜びを感じています。&lt;/p&gt;</description>
    </item>
    <item>
      <title>11時間のプロセスを37分に短縮した方法</title>
      <link>http://localhost:1313/jp/como-pasamos-un-proceso-de-11-horas-a-37-minutos/</link>
      <pubDate>Fri, 20 Jan 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/jp/como-pasamos-un-proceso-de-11-horas-a-37-minutos/</guid>
      <description>&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;&#xA;&lt;p&gt;この記事は、ウリセスが書いた &lt;a href=&#34;https://ulisesantana.dev/blog/2022/como-pase-un-proceso-en-nodejs-de-5-horas-a-5-minutos/&#34;&gt;5時間のプロセスを5分に短縮した方法&lt;/a&gt; に非常によく似ていますが、文脈が異なります。ここではNodeJSのコードを最適化するのではなく、データエンジニアリングにおけるPythonの適用について扱っており、今回は &lt;strong&gt;11時間かかっていたプロセスを37分に短縮&lt;/strong&gt; しました。まずは少し背景を説明させてください。&lt;/p&gt;&#xA;&lt;h3 id=&#34;問題点冬が来る&#34;&gt;問題点（冬が来る）&lt;/h3&gt;&#xA;&lt;p&gt;現在、私たちは &lt;a href=&#34;https://airflow.apache.org/&#34;&gt;Apache Airflow&lt;/a&gt; というツールを使用してプロセスの自動化を管理しています。これを使うと、crontabでプロセスの実行スケジュールを設定でき、自動的に実行され、Pythonコードで定義されたタスクを実行します。&lt;/p&gt;&#xA;&lt;p&gt;私たちの多くのプロセスのうちの1つは、プロバイダーからのデータ抽出と、その後ドメインに適応させるための変換です。このプロセスは通常 &lt;strong&gt;約5時間&lt;/strong&gt; かかっており、いくつかの理由である程度許容できるものでした：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;通常は夜間に自動で実行され、翌朝には完了している&lt;/li&gt;&#xA;&lt;li&gt;大量のデータを扱うため、すべての操作に時間がかかる&lt;/li&gt;&#xA;&lt;li&gt;リアルタイムで必要なわけではないので、他のチームにとっては重要ではない&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;以下のスクリーンショットは、プロセスが時々失敗することがあるものの、確認と修正で問題なく安定していることを示しています：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/proceso11horas-1.png&#34; alt=&#34;proceso11horas-1&#34; title=&#34; &#34;&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;そして冬が到来&#34;&gt;そして冬が到来&lt;/h3&gt;&#xA;&lt;p&gt;何らかの理由で、キューにさらに数百万件のレコードが追加され、実行時間が大幅に増加しました。具体的には、5時間から11時間に増加しました：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/proceso11horas-2.png&#34; alt=&#34;proceso11horas-2&#34; title=&#34; &#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;これは管理不可能で持続不可能な状態になっていました。ほぼ半日かかるプロセスが、24時間で2回も実行されるのです…計算してみてください。&lt;/p&gt;&#xA;&lt;h2 id=&#34;なぜこのようなことが起きたのか&#34;&gt;なぜこのようなことが起きたのか？&lt;/h2&gt;&#xA;&lt;p&gt;データ処理において定番のライブラリは &lt;a href=&#34;https://pandas.pydata.org/&#34;&gt;Pandas&lt;/a&gt; で、とてもよく機能します。しかし、大規模なデータセットに対してはパフォーマンスが悪くなります。そこで登場するのが &lt;a href=&#34;https://www.dask.org/&#34;&gt;Dask&lt;/a&gt; です — 大量のデータを効率的に処理するために設計されています。&lt;/p&gt;&#xA;&lt;p&gt;Daskは大規模データセットでPandasを上回る性能を発揮しますが、正しく使わないと扱いが難しい場合があります。ベストプラクティスを扱った書籍も多数あり、例えば &lt;a href=&#34;https://www.amazon.es/Data-Science-Scale-Python-Dask/dp/1617295604&#34;&gt;Data Science at Scale with Python and Dask&lt;/a&gt; があります。&lt;/p&gt;&#xA;&lt;p&gt;そのため、私たちはDaskの使い方に何か問題があるのではないかと考え、コードを見直すことにしました。&lt;/p&gt;&#xA;&lt;h2 id=&#34;謎の謎&#34;&gt;謎の謎&lt;/h2&gt;&#xA;&lt;p&gt;まず、プロセスが何をしているのかを確認しました：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;3つのデータセットを収集し、1つに統合して、データの出所に基づいた優先リストに従って処理します。これを &lt;strong&gt;&lt;code&gt;provider_rank_list&lt;/code&gt;&lt;/strong&gt; と呼びます（覚えておいてください、後で戻ってきます）。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;3つのソースデータセットは単一のファイルではなく、Daskが処理しやすいように分割されています。ここで気づいたのは、その分割が非常に小さいことです — &lt;strong&gt;各1〜2MBの1028パーティション&lt;/strong&gt;。これはDaskにとって致命的で、すべての利点が逆効果になってしまいます。&lt;/p&gt;&#xA;&lt;p&gt;私たちが実装した改善の1つは、1028パーティションをより大きなファイルにまとめることでした（ただし、Daskが効率的に動作できるように分割は維持）。&lt;/p&gt;&#xA;&lt;p&gt;ここで今日の重要なアドバイス：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Daskを使う場合、パーティションはデータ量に合わせて設定してください。あまりにも小さなパーティションが多すぎたり、大きすぎるパーティションが少なすぎたりしないようにしましょう。公式ドキュメントでは &lt;strong&gt;約100MBのパーティション&lt;/strong&gt; を推奨しています。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;考え方を示すコード例は以下の通りです：&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;&#xA;&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;&#xA;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&#xA;&lt;td class=&#34;lntd&#34;&gt;&#xA;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;input_dataset&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dask&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_dask&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path_to_file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;dataset_to_process&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input_dataset&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;repartition&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;partition_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_partition_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# Fix input to ensure it doesn’t break anything&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Lots&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;code&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;doing&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;other&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;things&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;result_dataframe&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;processed_dataset&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;repartition&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;partition_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_partition_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# Fix output size in case it grew during processing&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h2 id=&#34;なぜファイル数ではなくパーティションサイズを設定するのか&#34;&gt;なぜファイル数ではなくパーティションサイズを設定するのか？&lt;/h2&gt;&#xA;&lt;p&gt;良い質問です。Daskには2つのパーティション方法があります：&lt;code&gt;npartitions&lt;/code&gt; と &lt;code&gt;partition_size&lt;/code&gt;。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
